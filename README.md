# web-llm-eeve

Welcome to the `web-llm-eeve` project! This project demonstrates how to utilize the `yanolja/EEVE-Korean-Instruct-10.8B-v1.0` model from Hugging Face, quantized to 4-bit, and run it on a client's web GPU using the `mlc-ai/web-llm` framework. This example serves as a guide to effectively deploy and interact with the EEVE model in a web environment.

## Thanks to

- [yanolja/EEVE-Korean-Instruct-10.8B-v1.0 model](https://github.com/mlc-ai/web-llm)
- [MLC-AI's web-llm framework](https://huggingface.co/yanolja/EEVE-Korean-Instruct-10.8B-v1.0)

## How to use

Clone the repository

```
git clone https://github.com/pfldy2850/web-llm-eeve.git
cd web-llm-eeve
```

Install dependencies

```
npm install
```

Run the web application

```
npm start
```

Then, the server starts to run at http://localhost:8883
